# app.py
# --------------------------- Imports ---------------------------
import os
import re
import time
import random
from collections import deque

import pandas as pd
import streamlit as st

# RAG / LangChain
from langchain_community.document_loaders import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_openai import ChatOpenAI  # â¬…ï¸ LLM ì‚¬ìš©

# --------------------------- App Config ---------------------------
st.set_page_config(page_title="ìš´ë™í™” ì‡¼í•‘ ì—ì´ì „íŠ¸")
st.title("ìš´ë™í™” ì‡¼í•‘ ì—ì´ì „íŠ¸")
os.environ["OPENAI_API_KEY"] = st.secrets.get("OPENAI_API_KEY", "")

# LLM ì„¤ì • (í•„ìš”ì‹œ ë°”ê¾¸ì„¸ìš”)
USE_LLM_DESC = True
LLM_MODEL = "gpt-4o-mini"
LLM_TEMPERATURE = 0.4
LLM_MAX_TOKENS = 160  # 1~2ë¬¸ì¥

# ë§¤ ì¶”ì²œ ì¶œë ¥ ì‹œ í•¨ê»˜ ë³´ì—¬ì¤„ ì•ˆë‚´ ë¬¸êµ¬
PREFACE = "ë„¤ ì•Œê² ìŠµë‹ˆë‹¤. ê·€í•˜ì˜ ì§ˆë¬¸ì— ë§ëŠ” ìš´ë™í™”ë¥¼ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

# ì„¸ì…˜ ìƒíƒœ
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "store" not in st.session_state:
    st.session_state["store"] = dict()
if "selected_question" not in st.session_state:
    st.session_state["selected_question"] = None
if "followup_step" not in st.session_state:
    st.session_state["followup_step"] = 0
if "seen_products" not in st.session_state:
    st.session_state["seen_products"] = set()  # "ë¸Œëœë“œ||ì œí’ˆëª…"
if "random_pool" not in st.session_state:
    st.session_state["random_pool"] = None  # ìµœì´ˆ ë¡œë“œ í›„ ì±„ì›€

SESSION_ID = "sneaker-chat"
CSV_PATH = "shoes_top12.csv"  # íŒŒì¼ëª… ë§ê²Œ ë³€ê²½ ê°€ëŠ¥

# --------------------------- í›„ì†ì§ˆë¬¸(ê³ ì • 6ê°œ) ---------------------------
followup_set_1 = {
    "Q1": "ê°€ë²¼ìš´ ìš´ë™í™”ëŠ” ì–´ë–¤ ì œí’ˆì´ ìˆë‚˜ìš”?",
    "Q2": "ë¬´ê²Œê° ìˆê³  ì•ˆì •ê° ìˆëŠ” ì œí’ˆì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
    "Q3": "í†µí’ì´ ì¢‹ì€ ìš´ë™í™” ì œí’ˆì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
}
followup_set_2 = {
    "Q4": "ì¿ ì…˜ê°ì´ ì¢‹ì€ ì œí’ˆì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
    "Q5": "í‰í‰í•œ ìš´ë™í™”ëŠ” ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
    "Q6": "ì•½ê°„ì˜ êµ½ì´ ìˆëŠ” ì œí’ˆì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
}

# --------------------------- ë°ì´í„°/RAG ì¤€ë¹„ ---------------------------
@st.cache_resource(show_spinner=True)
def load_product_df(path: str) -> pd.DataFrame:
    df = pd.read_csv(path, encoding="utf-8")
    # êµ¬ë§¤ë§í¬ ì—†ëŠ” í–‰ ì œì™¸
    df = df[df["êµ¬ë§¤ë§í¬"].notna() & (df["êµ¬ë§¤ë§í¬"].astype(str).str.strip() != "")].copy()
    df.reset_index(drop=True, inplace=True)
    return df

df_products = load_product_df(CSV_PATH)

# ì„¸ì…˜ ëœë¤ í’€ ì´ˆê¸°í™”
if st.session_state["random_pool"] is None:
    st.session_state["random_pool"] = deque(range(len(df_products)))
    random.shuffle(st.session_state["random_pool"])

@st.cache_resource(show_spinner=True)
def build_retriever(csv_path: str):
    loader = CSVLoader(csv_path, encoding="utf-8")
    docs = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
    splits = splitter.split_documents(docs)
    embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vs = FAISS.from_documents(splits, embedding=embedding)
    return vs.as_retriever(search_kwargs={"k": 20})

retriever = build_retriever(CSV_PATH)

# --------------------------- ìœ í‹¸ í•¨ìˆ˜ ---------------------------
def stream_text(text: str, delay: float = 0.015):
    ph = st.empty()
    buf = ""
    for chunk in re.split(r"(\s+)", text):  # ê³µë°± ë³´ì¡´
        buf += chunk
        ph.markdown(buf)
        time.sleep(delay)

def _norm(s: str) -> str:
    s = str(s).lower()
    s = re.sub(r"[\s\-\u2013_/\\.,()]+", "", s)
    return s

def product_key(brand: str, name: str) -> str:
    return f"{_norm(brand)}||{_norm(name)}"

def _md_link(url: str, label: str = "êµ¬ë§¤ë§í¬") -> str:
    u = str(url).strip()
    if not u:
        return ""
    if not re.match(r"^https?://", u, re.IGNORECASE):
        u = "http://" + u
    return f"[{label}]({u})"

def draw_random_products(n: int = 3) -> str:
    pool: deque = st.session_state["random_pool"]
    chosen_idx = []
    target = min(n, len(df_products))
    while len(chosen_idx) < target:
        if not pool:
            pool.extend(range(len(df_products)))
            random.shuffle(pool)
        idx = pool.popleft()
        row = df_products.iloc[idx]
        key = product_key(row["ë¸Œëœë“œ"], row["ì œí’ˆëª…"])
        if key in st.session_state["seen_products"]:
            continue
        chosen_idx.append(idx)

    lines = []
    for i, idx in enumerate(chosen_idx, start=1):
        row = df_products.iloc[idx]
        st.session_state["seen_products"].add(product_key(row["ë¸Œëœë“œ"], row["ì œí’ˆëª…"]))
        link_md = _md_link(row["êµ¬ë§¤ë§í¬"], "êµ¬ë§¤ë§í¬")
        # âœ… ê°€ê²© ë’¤ ì¤„ë°”ê¿ˆ(ë§ˆí¬ë‹¤ìš´ ê°•ì œ ê°œí–‰: ê³µë°± 2ê°œ + \n)
        lines.append(
            f"{i}. {row['ë¸Œëœë“œ']} {row['ì œí’ˆëª…']} | {row['ê°€ê²©']} |  \n {row['ì œí’ˆì„¤ëª…']} | {link_md}"
        )
    return "\n".join(lines)

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = ChatMessageHistory()
    return st.session_state["store"][session_id]

def build_query_from_history_and_input(history: BaseChatMessageHistory, user_input: str, max_turns: int = 4) -> str:
    msgs = history.messages[-max_turns * 2 :] if hasattr(history, "messages") else []
    hist_text = []
    for m in msgs:
        role = getattr(m, "type", getattr(m, "role", ""))
        content = getattr(m, "content", "")
        if role in ("human", "user", "ai", "assistant"):
            hist_text.append(f"{role}: {content}")
    hist_blob = "\n".join(hist_text)
    return f"{hist_blob}\nuser: {user_input}\n\nìš”ì•½ í‚¤ì›Œë“œ: ìš´ë™ ëª©ì , ì¿ ì…˜, í†µí’, ê²½ëŸ‰/ì•ˆì •, êµ½ ë†’ì´, ë¸Œëœë“œ ì„ í˜¸"

def filter_unseen_docs(docs):
    filtered = []
    for d in docs:
        t = d.page_content
        brand_m = re.search(r"ë¸Œëœë“œ\s*[:=]\s*(.+)", t)
        name_m = re.search(r"ì œí’ˆëª…\s*[:=]\s*(.+)", t)
        brand = brand_m.group(1).strip() if brand_m else ""
        name = name_m.group(1).strip() if name_m else ""
        if product_key(brand, name) not in st.session_state["seen_products"]:
            filtered.append(d)
    return filtered

def docs_to_rows(docs):
    items = []
    local_keys = set()
    for d in docs:
        t = d.page_content
        def grab(field):
            m = re.search(rf"{field}\s*[:=]\s*(.+)", t)
            return m.group(1).strip() if m else ""
        brand = grab("ë¸Œëœë“œ")
        name = grab("ì œí’ˆëª…")
        price = grab("ê°€ê²©")
        desc = grab("ì œí’ˆì„¤ëª…")
        url = grab("êµ¬ë§¤ë§í¬")
        if not url:
            continue
        key = product_key(brand, name)
        if key in local_keys:
            continue
        local_keys.add(key)
        items.append({"brand": brand, "name": name, "price": price, "desc": desc, "url": url})
    return items

def topup_with_unseen(rows, need: int):
    if need <= 0:
        return rows
    have_keys = {product_key(r["brand"], r["name"]) for r in rows}
    candidates = []
    for _, r in df_products.iterrows():
        key = product_key(r["ë¸Œëœë“œ"], r["ì œí’ˆëª…"])
        if key in have_keys or key in st.session_state["seen_products"]:
            continue
        candidates.append(
            {"brand": r["ë¸Œëœë“œ"], "name": r["ì œí’ˆëª…"], "price": r["ê°€ê²©"], "desc": r["ì œí’ˆì„¤ëª…"], "url": r["êµ¬ë§¤ë§í¬"]}
        )
    random.shuffle(candidates)
    rows.extend(candidates[:need])
    return rows

# ---------- í‚¤ì›Œë“œ ë§¤í•‘ & ë­í‚¹ ----------
def get_keywords(user_input: str):
    ui = str(user_input).lower()
    if ("ê°€ë²¼ìš´" in ui) or ("ê²½ëŸ‰" in ui) or ("light" in ui):
        return ["ê°€ë²¼ìš´", "ê²½ëŸ‰", "ë¼ì´íŠ¸", "light", "ë¯¼ì²©", "ë¹ ë¥¸", "ë ˆì´ì‹±"]
    if ("ë¬´ê²Œê°" in ui) or ("ì•ˆì •ê°" in ui) or ("ì§€ì§€" in ui) or ("support" in ui):
        return ["ì•ˆì •", "ì•ˆì •ê°", "ì§€ì§€", "ì„œí¬íŠ¸", "ë°œëª©ì§€ì§€", "ê²¬ê³ ", "ë¡œì»¤", "ì»¨íŠ¸ë¡¤"]
    if ("í†µí’" in ui) or ("ë©”ì‰¬" in ui) or ("ë©”ì‹œ" in ui) or ("breath" in ui):
        return ["í†µí’", "ë©”ì‰¬", "ë©”ì‹œ", "í†µê¸°", "ì‹œì›", "ì—ì–´ë¦¬"]
    if "ì¿ ì…˜" in ui or "ì¶©ê²©" in ui or "ë¶€ë“œëŸ½" in ui:
        return ["ì¿ ì…˜", "ì¶©ê²©", "í¡ìˆ˜", "ë¶€ë“œëŸ½", "í­ì‹ ", "ì†Œí”„íŠ¸", "í¸ì•ˆ"]
    if ("í‰í‰" in ui) or ("í”Œë«" in ui) or ("ë‚®ì€ êµ½" in ui) or ("ë¡œìš°ë“œë¡­" in ui):
        return ["í‰í‰", "í”Œë«", "ë‚®ì€êµ½", "ë¡œìš°ë“œë¡­", "0mm", "4mm", "í”Œë«ì†”"]
    if "êµ½" in ui or "ë“œë¡­" in ui or "ë†’" in ui:
        return ["êµ½", "ë“œë¡­", "í", "ë†’ì´", "ííˆ¬í† ", "stack"]
    return []

def keyword_score(text: str, keywords: list[str]) -> int:
    if not keywords:
        return 0
    t = str(text).lower()
    score = 0
    for kw in keywords:
        k = kw.lower()
        score += t.count(k)
    return score

def rank_by_keywords(df: pd.DataFrame, keywords: list[str], exclude_keys: set[str], top_k: int = 12):
    if not keywords:
        return []
    rows = []
    for _, r in df.iterrows():
        key = product_key(r["ë¸Œëœë“œ"], r["ì œí’ˆëª…"])
        if key in exclude_keys:
            continue
        if not isinstance(r.get("êµ¬ë§¤ë§í¬", ""), str) or not r["êµ¬ë§¤ë§í¬"].strip():
            continue
        name_desc = f"{r['ë¸Œëœë“œ']} {r['ì œí’ˆëª…']} {r['ì œí’ˆì„¤ëª…']}"
        sc = keyword_score(name_desc, keywords)
        if sc <= 0:
            continue
        rows.append({
            "brand": r["ë¸Œëœë“œ"], "name": r["ì œí’ˆëª…"], "price": r["ê°€ê²©"],
            "desc": r["ì œí’ˆì„¤ëª…"], "url": r["êµ¬ë§¤ë§í¬"], "score": sc
        })
    random.shuffle(rows)
    rows.sort(key=lambda x: x["score"], reverse=True)
    for r in rows:
        r.pop("score", None)
    return rows[:top_k]

def rows_to_output(rows):
    # âœ… ê°€ê²© ë’¤ ì¤„ë°”ê¿ˆ(ê³µë°± 2ê°œ + \n) ì ìš©
    return "\n".join(
        f"{i}. {r['brand']} {r['name']} | {r['price']} |  \n {r['desc']} | {_md_link(r['url'], 'êµ¬ë§¤ë§í¬')}"
        for i, r in enumerate(rows, start=1)
    )

# ---------- ì§ˆë¬¸ ë§¥ë½ ë§ì¶¤ ì„¤ëª… ìƒì„± (LLM) ----------
def _get_llm():
    try:
        return ChatOpenAI(model=LLM_MODEL, temperature=LLM_TEMPERATURE, max_tokens=LLM_MAX_TOKENS)
    except Exception:
        return None

LLM = _get_llm()

LLM_SYSTEM = (
    "ë‹¹ì‹ ì€ ëŸ¬ë‹í™” ì¶”ì²œ ì„¤ëª…ì„ ì‘ì„±í•˜ëŠ” ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤. "
    "ë‹¤ìŒ ì œí’ˆ ì •ë³´ì™€ ê¸°ë³¸ ì„¤ëª…ë§Œì„ ê·¼ê±°ë¡œ, ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„(ì˜ˆ: ê¸°ë¡ ë‹¨ì¶•/ì¥ê±°ë¦¬, í†µí’, ì•ˆì •ê° ë“±)ì™€ "
    "ì—°ê²°ë˜ê²Œ í•œêµ­ì–´ë¡œ 1~2ë¬¸ì¥ ìš”ì•½ì„ ë§Œë“­ë‹ˆë‹¤. "
    "CSVì— ì—†ëŠ” ìˆ˜ì¹˜ë‚˜ ê¸°ëŠ¥ì€ ì¶”ì¸¡í•´ ì“°ì§€ ë§ˆì„¸ìš”. ê³¼ì¥ëœ í‘œí˜„ ëŒ€ì‹  ëª…ë£Œí•œ ì¥ì ë§Œ ì“°ê³ , ë¬¸ì¥ ëì— ë§ˆì¹¨í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
)

def generate_contextual_descriptions(user_question: str, rows: list[dict]) -> list[dict]:
    if not USE_LLM_DESC or LLM is None or not os.environ.get("OPENAI_API_KEY"):
        return rows

    new_rows = []
    for r in rows:
        try:
            base_desc = str(r.get("desc", "")).strip()
            brand = r.get("brand", "")
            name = r.get("name", "")
            price = r.get("price", "")

            user_content = (
                f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_question}\n\n"
                f"[ì œí’ˆ]\në¸Œëœë“œ: {brand}\nì œí’ˆëª…: {name}\nê°€ê²©: {price}\n\n"
                f"[ê¸°ë³¸ ì„¤ëª…]\n{base_desc}\n\n"
                f"[ì‘ì„±]\n- ì§ˆë¬¸ì— ë„ì›€ì´ ë˜ëŠ” í¬ì¸íŠ¸ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n"
                f"- CSV ì„¤ëª…ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                f"- ì˜ˆ: ê¸°ë¡ ë‹¨ì¶•/ì§€ì†ì£¼/í†µí’/ì•ˆì •ê°/ì¿ ì…˜/ê²½ëŸ‰ ì¤‘ í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ë§Œ ì—°ê²°."
            )

            resp = LLM.invoke([{"role": "system", "content": LLM_SYSTEM},
                               {"role": "user", "content": user_content}])
            text = (getattr(resp, "content", "") or "").strip()
            if not text:
                text = base_desc
            text = re.sub(r"\s+", " ", text)
            r = {**r, "desc": text}
        except Exception:
            pass
        new_rows.append(r)
    return new_rows

# --------------------------- ì´ì „ ëŒ€í™” ì¶œë ¥ ---------------------------
for role, msg in st.session_state["messages"]:
    st.chat_message(role).write(msg)

# --------------------------- ì…ë ¥ ---------------------------
def _hide_chat_input_css():
    st.markdown(
        "<style>div[data-testid='stChatInput']{display:none !important;}</style>",
        unsafe_allow_html=True,
    )

# âœ… í›„ì†ì§ˆë¬¸ íŒ¨ë„ì´ ë³´ì´ëŠ” ë™ì•ˆì—ëŠ” ì…ë ¥ì°½ ìì²´ë¥¼ ë Œë”ë§í•˜ì§€ ì•ŠìŒ
FOLLOWUP_ACTIVE = st.session_state["followup_step"] in (1, 2)

user_input = None
if st.session_state["selected_question"]:
    user_input = st.session_state["selected_question"]
    st.session_state["selected_question"] = None
else:
    if FOLLOWUP_ACTIVE:
        _hide_chat_input_css()  # í˜¹ì‹œ ë‚¨ì•„ìˆëŠ” ì…ë ¥ì°½ë„ ì¦‰ì‹œ ìˆ¨ê¹€
        user_input = None
    else:
        tmp = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”", key="main_input")
        if tmp:
            user_input = tmp

# --------------------------- ì‘ë‹µ ì²˜ë¦¬ ---------------------------
if user_input:
    # ì‚¬ìš©ì ë§í’ì„ ì€ í•­ìƒ í‘œì‹œ (ì²« ì¶”ì²œ í¬í•¨)
    st.chat_message("user").write(user_input)
    st.session_state["messages"].append(("user", user_input))

    # ì²« ìš”ì²­ì¸ì§€ íŒë³„
    is_first_trigger = (user_input.strip() == "ìš´ë™í™” ì¶”ì²œí•´ì¤˜" and st.session_state["followup_step"] == 0)

    # ì²« ìš”ì²­: í”„ë¦¬í˜ì´ìŠ¤ ì œê±°í•˜ê³  ì¶”ì²œë§Œ ì¶œë ¥
    if is_first_trigger:
        random_reco = draw_random_products(3)
        combined = random_reco  # âœ… í”„ë¦¬í˜ì´ìŠ¤ ì œê±°
        with st.chat_message("assistant"):
            stream_text(combined, delay=0.015)
        st.session_state["messages"].append(("assistant", combined))
        st.session_state["followup_step"] = 1
        st.rerun()  # â–¶ íŒ¨ë„ì´ ë°”ë¡œ ëœ¨ëŠ” í„´ì—ì„œ ì…ë ¥ì°½ ìˆ¨ê¹€

    else:
        # 0) í‚¤ì›Œë“œ ë­í‚¹
        keywords = get_keywords(user_input)
        exclude = set(st.session_state["seen_products"])
        rows = rank_by_keywords(df_products, keywords, exclude_keys=exclude, top_k=12)[:3]

        # 1) ë²¡í„°ê²€ìƒ‰ ë³´ì¶©
        if len(rows) < 3:
            history = get_session_history(SESSION_ID)
            query = build_query_from_history_and_input(history, user_input)
            rag_docs = retriever.get_relevant_documents(query)
            rag_docs_filtered = filter_unseen_docs(rag_docs)
            extra = []
            existing_keys = {product_key(r["brand"], r["name"]) for r in rows}
            for r in docs_to_rows(rag_docs_filtered):
                k = product_key(r["brand"], r["name"])
                if k not in existing_keys and k not in exclude:
                    extra.append(r)
                    existing_keys.add(k)
                if len(rows) + len(extra) >= 3:
                    break
            rows.extend(extra)

        # 2) CSV ë¯¸ë³¸ ë³´ì¶©
        if len(rows) < 3:
            rows = topup_with_unseen(rows, 3 - len(rows))
        rows = rows[:3]

        # 3) seen ë“±ë¡
        for r in rows:
            st.session_state["seen_products"].add(product_key(r["brand"], r["name"]))

        # 4) LLM ìš”ì•½ ì„¤ëª…
        rows = generate_contextual_descriptions(user_input, rows)

        # 5) ì¶œë ¥ (ì´í›„ í„´ë¶€í„°ëŠ” í”„ë¦¬í˜ì´ìŠ¤ í¬í•¨)
        out_text = rows_to_output(rows)
        combined = f"{PREFACE}\n\n{out_text}"
        with st.chat_message("assistant"):
            stream_text(combined, delay=0.015)
        st.session_state["messages"].append(("assistant", combined))

        # 6) íŒ¨ë„ ë‹¨ê³„ ì§„í–‰ ë° ì¢…ë£Œ ì•ˆë‚´
        if st.session_state["followup_step"] == 1:
            st.session_state["followup_step"] = 2
            st.rerun()  # â–¶ ë‘ ë²ˆì§¸ íŒ¨ë„ë„ ì¦‰ì‹œ ë°˜ì˜
        elif st.session_state["followup_step"] == 2:
            st.session_state["followup_step"] = 3
            code = "8172"  # ğŸ”’ ì¸ì¦ë²ˆí˜¸ë¥¼ í•­ìƒ 8172ë¡œ ê³ ì •
            end_msg = f"ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¸ì¦ë²ˆí˜¸ëŠ” {code} ì…ë‹ˆë‹¤"
            st.chat_message("assistant").write(end_msg)
            st.session_state["messages"].append(("assistant", end_msg))

# --------------------------- í›„ì†ì§ˆë¬¸ íŒ¨ë„ ---------------------------
def render_followup_panel(step: int):
    if step not in (1, 2):
        return
    st.markdown("### ì´ëŸ° ì§ˆë¬¸ë„ í•´ë³´ì„¸ìš”!")
    qset = followup_set_1 if step == 1 else followup_set_2
    for key, question in qset.items():
        col_q, col_btn = st.columns([8, 1])
        col_q.markdown(f"**{key}.** {question}")
        if col_btn.button("â•", key=f"btn_{key}"):
            st.session_state["selected_question"] = question
            st.rerun()

render_followup_panel(st.session_state["followup_step"])
